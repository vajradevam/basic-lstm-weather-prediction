{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-08 05:57:42.290621: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-08 05:57:42.320951: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-08 05:57:42.477099: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-08 05:57:42.478821: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-08 05:57:43.193730: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2376/1917579783.py:5: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['Date & Time'] = pd.to_datetime(df['Date & Time'])\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "import pandas as pd\n",
    "\n",
    "df = read_csv('./data/data.csv')\n",
    "df['Date & Time'] = pd.to_datetime(df['Date & Time'])\n",
    "df.set_index('Date & Time', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 43258 entries, 2024-01-23 13:00:00 to 2024-06-28 17:35:00\n",
      "Data columns (total 16 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Inside Temp – C         43258 non-null  int64  \n",
      " 1   High Inside Temp – C    43258 non-null  int64  \n",
      " 2   Low Inside Temp – C     43258 non-null  int64  \n",
      " 3   Inside Hum - %          43258 non-null  int64  \n",
      " 4   High Inside Hum - %     43258 non-null  int64  \n",
      " 5   Low Inside Hum - %      43258 non-null  int64  \n",
      " 6   Inside Dew Point – C    43258 non-null  int64  \n",
      " 7   Inside Heat Index – C   43258 non-null  int64  \n",
      " 8   Barometer - mb          43258 non-null  float64\n",
      " 9   High Bar - mb           43258 non-null  float64\n",
      " 10  Low Bar - mb            43258 non-null  float64\n",
      " 11  Absolute Pressure - mb  43258 non-null  float64\n",
      " 12  Low Wind Chill – C      43258 non-null  object \n",
      " 13  Heat Index – C          43258 non-null  object \n",
      " 14  Heating Degree Days     43258 non-null  object \n",
      " 15  Cooling Degree Days     43258 non-null  object \n",
      "dtypes: float64(4), int64(8), object(4)\n",
      "memory usage: 5.6+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2376/1157609063.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.replace('--', pd.NA, inplace=True)\n",
      "/tmp/ipykernel_2376/1157609063.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "cols = ['Inside Temp – C',\n",
    " 'High Inside Temp – C',\n",
    " 'Low Inside Temp – C',\n",
    " 'Inside Hum - %',\n",
    " 'High Inside Hum - %',\n",
    " 'Low Inside Hum - %',\n",
    " 'Inside Dew Point – C',\n",
    " 'Inside Heat Index – C',\n",
    " 'Barometer - mb',\n",
    " 'High Bar - mb',\n",
    " 'Low Bar - mb',\n",
    " 'Absolute Pressure - mb',\n",
    " 'Low Wind Chill – C',\n",
    " 'Heat Index – C',\n",
    " 'Heating Degree Days',\n",
    " 'Cooling Degree Days']\n",
    "\n",
    "data = df[cols]\n",
    "\n",
    "data.replace('--', pd.NA, inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.values\n",
    "dataset = dataset.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36769, 16)\n",
      "(6489, 16)\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(dataset) * 0.85)\n",
    "\n",
    "train, test = dataset[:train_size], dataset[train_size:]\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(dataset, n_steps = 1):\n",
    "    x,  y = [], []\n",
    "\n",
    "    for i in range(len(dataset) - n_steps):\n",
    "        xs = dataset[i: (i + n_steps)]\n",
    "        ys = dataset[i + n_steps]\n",
    "\n",
    "        x.append(xs)\n",
    "        y.append(ys)\n",
    "\n",
    "    return np.array(x), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36763, 6, 16)\n",
      "(6483, 6, 16)\n",
      "(36763, 16)\n",
      "(6483, 16)\n",
      "[[0.07692301 0.07692301 0.07692301 0.3076923  0.3023256  0.28205132\n",
      "  0.16666669 0.         0.75084305 0.7575798  0.7474747  0.746624\n",
      "  0.25925928 0.18421054 0.         0.6117647 ]\n",
      " [0.07692301 0.07692301 0.07692301 0.2051282  0.25581396 0.23076928\n",
      "  0.05555558 0.         0.7407417  0.7474785  0.73737335 0.73986435\n",
      "  0.25925928 0.21052629 0.         0.63529414]\n",
      " [0.07692301 0.07692301 0.07692301 0.2051282  0.25581396 0.2051282\n",
      "  0.05555558 0.         0.7306404  0.73737717 0.7306404  0.7297325\n",
      "  0.2962963  0.21052629 0.         0.6470588 ]\n",
      " [0.07692301 0.07692301 0.07692301 0.23076916 0.2093023  0.23076928\n",
      "  0.1111111  0.04166669 0.7205391  0.7306442  0.7205391  0.71959305\n",
      "  0.2962963  0.21052629 0.         0.65882355]\n",
      " [0.15384614 0.15384614 0.07692301 0.25641024 0.23255813 0.25641024\n",
      "  0.16666669 0.04166669 0.71717453 0.71717453 0.71717453 0.71621704\n",
      "  0.2962963  0.21052629 0.         0.6823529 ]\n",
      " [0.15384614 0.15384614 0.15384614 0.2820512  0.25581396 0.28205132\n",
      "  0.16666669 0.08333337 0.71380615 0.71717453 0.71380615 0.7128372\n",
      "  0.2962963  0.21052629 0.         0.6705882 ]]\n",
      "[0.15384614 0.15384614 0.15384614 0.3076923  0.3023256  0.3076923\n",
      " 0.22222221 0.08333337 0.7104378  0.7104416  0.7104378  0.7094574\n",
      " 0.2962963  0.21052629 0.         0.6823529 ]\n"
     ]
    }
   ],
   "source": [
    "n_steps = 6\n",
    "\n",
    "train_x, train_y = split_sequences(train, n_steps)\n",
    "test_x, test_y = split_sequences(test, n_steps)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(test_x.shape)\n",
    "\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_y[0])\n",
    "\n",
    "test_y = scaler.inverse_transform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = train_x.shape[2]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True, input_shape=(n_steps, n_features)))\n",
    "model.add(LSTM(100, activation='relu'))\n",
    "model.add(Dense(n_features))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(train_x, train_y, epochs=40, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.00120583e+01 3.00936356e+01 2.98708973e+01 5.98232422e+01\n",
      "  6.01069450e+01 6.00588646e+01 2.11013794e+01 3.23600197e+01\n",
      "  1.00771783e+03 1.00773462e+03 1.00763037e+03 9.99041931e+02\n",
      "  3.06763878e+01 4.04404106e+01 5.75654558e-05 4.31326404e-02]\n",
      " [2.98919868e+01 3.00475044e+01 2.96275520e+01 5.99420013e+01\n",
      "  6.02196693e+01 6.00571442e+01 2.11192036e+01 3.22158966e+01\n",
      "  1.00771600e+03 1.00775317e+03 1.00762134e+03 9.99024414e+02\n",
      "  3.01731300e+01 4.02356339e+01 4.75648085e-05 4.23883609e-02]]\n",
      "[[2.99999981e+01 2.99999981e+01 2.90000019e+01 6.00000000e+01\n",
      "  5.99999962e+01 6.00000000e+01 2.10000000e+01 3.20000000e+01\n",
      "  1.00760004e+03 1.00760004e+03 1.00760004e+03 9.99000000e+02\n",
      "  3.00000019e+01 4.00000000e+01 0.00000000e+00 4.19999994e-02]\n",
      " [2.99999981e+01 2.99999981e+01 2.99999981e+01 6.00000000e+01\n",
      "  5.99999962e+01 6.00000000e+01 2.10000000e+01 3.20000000e+01\n",
      "  1.00760004e+03 1.00760004e+03 1.00750000e+03 9.98899963e+02\n",
      "  3.00000019e+01 4.00000000e+01 0.00000000e+00 4.19999994e-02]]\n"
     ]
    }
   ],
   "source": [
    "yhat = scaler.inverse_transform(model.predict(test_x, verbose=0)) \n",
    "print(yhat[:2])\n",
    "print(test_y[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17130911\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(mean_squared_error(y_true=test_y, y_pred=yhat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VENV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
